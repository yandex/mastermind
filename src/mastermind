#!/usr/bin/python
from datetime import datetime
import inspect
import json
from json import dumps
import logging
from logging.handlers import SysLogHandler
import os
import os.path
from pprint import pprint
import re
import socket
import subprocess
import sys
from time import sleep
from functools import wraps

import msgpack

from opster import Dispatcher
from cocaine.exceptions import ServiceError
from cocaine.services import Service

try:
    from cocaine.exceptions import DisconnectionError
except ImportError:
    from cocaine.asio.exceptions import DisconnectionError


SERVICE_APP_NAME = 'mastermind2.26'
SERVICE_DEFAULT_HOST = 'localhost'
SERVICE_DEFAULT_PORT = 10053

host_param = ['h',
              'host',
              '{host}:{port}'.format(host=SERVICE_DEFAULT_HOST,
                                     port=SERVICE_DEFAULT_PORT),
              'Mastermind application host[:port]']

app_param = ('a',
             'app',
             '{app}'.format(app=SERVICE_APP_NAME),
             'Mastermind application name')


def logger_setup():
    logger = logging.getLogger('mastermind.commands')
    logger_h = SysLogHandler()
    logger_h.setFormatter(logging.Formatter(fmt='%(name)-15s %(message)s'))
    logger.addHandler(logger_h)
    logger.setLevel(logging.INFO)
    return logger


logger = logger_setup()


class ReconnectableService(object):
    def __init__(self, app_name, host=None, port=None):
        self.app_name = app_name
        self.host = host
        self.port = port
        self.connect_service()

    def connect_service(self):
        self.backend = Service(self.app_name, host=self.host, port=self.port)

    def enqueue(self, method, data):
        return ReconnectableChain(self, method, data)


class ReconnectableChain(object):
    def __init__(self, service, method, data):
        self.service = service
        self.method = method
        self.data = data
        self._create_chain()

    def _create_chain(self):
        self.chain = self.service.backend.enqueue(self.method, self.data)

    def get(self):
        try:
            return self.chain.get()
        except DisconnectionError:
            sleep(3)
            self.service.connect_service()
            self._create_chain()
            return self.chain.get()


def service(host, app):
    parts = host.split(':', 1)
    hostname, port = parts[0], len(parts) == 2 and int(parts[1]) or SERVICE_DEFAULT_PORT
    return ReconnectableService(app or SERVICE_APP_NAME, host=hostname, port=port)


def log_action(func):

    def decorator(func, *args, **kwargs):
        logger.info(' '.join(sys.argv))
        return func(*args, **kwargs)

    return evil_wrapper(func, decorator)


def evil_wrapper(func, decorator):
    '''This evil code is required to be able to decorate opster dispacher
    commands. This workaround helps "inspect" module to parse
    command arguments properly'''

    args = inspect.getargspec(func)
    arglist = args[0][:-len(args[3])]
    kwarglist = zip(args[0][-len(args[3]):], args[3])

    argstr = ', '.join(arglist) + (', ' if arglist else '')
    wrapper = "def wrapper(%s %s):\n    return wrapped(func, %s %s)\n" % (argstr,
        ', '.join([kw[0] + '=' + str(kw[1]) for kw in kwarglist]), argstr,
        ', '.join([kw[0] + '=' + kw[0] for kw in kwarglist]))
    wrapper_code = compile(wrapper, '<string>', 'exec')
    fakeglobals = {}
    eval(wrapper_code, {'wrapped': decorator, 'func': func}, fakeglobals)
    f_with_good_sig = fakeglobals['wrapper']

    return wraps(func)(f_with_good_sig)


DT_FORMAT = '%Y-%m-%d %H:%M:%S'


def ts_to_dt(ts):
    dt = datetime.fromtimestamp(ts)
    return dt.strftime(DT_FORMAT)


# group commands
groupDispatcher = Dispatcher(globaloptions=(host_param, app_param))

def to_gb(bytes):
    return bytes / (1024.0 * 1024.0 * 1024.0)

def convert_stats(d):
    for k in ('free_space', 'free_effective_space', 'used_space', 'total_space'):
        if k in d:
            d[k] = '{0:.3f} Gb'.format(to_gb(d[k]))


@groupDispatcher.command(name='info')
@log_action
def group_info(group, history=('l', False, 'History of group nodes'), host=None, app=None):
    '''Get group info'''
    s = service(host, app)
    group = int(group)

    res = s.enqueue("get_group_info", msgpack.packb(group)).get()
    for node in res.get('node_backends', []):
        convert_stats(node)
    pprint(res)

    if history:

        group_history = s.enqueue('get_group_history', msgpack.packb([group])).get()
        if isinstance(group_history, dict) and not 'nodes' in group_history:
            # exception returned
            print group_history
        else:
            if group_history['couples']:
                print
                print color('Couples history:', YELLOW)
                for entry in group_history['couples']:
                    record = '[{timestamp}] {couple}'.format(**entry)
                    print record
            print
            print color('Nodes history:', YELLOW)
            for entry in group_history['nodes']:
                record = '[{timestamp}] {set}'.format(**entry)
                if entry['type'] == 'manual':
                    record += ', MANUAL'
                    record = color(record, YELLOW)
                elif entry['type'] == 'job':
                    record += ', JOB'
                    record = color(record, BLUE)
                print record


@groupDispatcher.command(name='meta')
@log_action
def group_meta(group, key=('k', '', 'Read data from arbitrary key'),
               unpack=('u', False, 'Unpack key with msgpack'), host=None, app=None):
    '''Read group metadata'''
    s = service(host, app)
    group = int(group)

    params = [group, key, unpack]

    res = s.enqueue('get_group_meta', msgpack.packb(params)).get()
    pprint(res)


@groupDispatcher.command(name='next-number')
@log_action
def group_next_number(count, host=None, app=None):
    '''Get unused group numbers, number of groups is an argument'''
    s = service(host, app)
    count = int(count)

    res = s.enqueue("get_next_group_number", msgpack.packb(count)).get()
    print res


@groupDispatcher.command(name='list-uncoupled')
@log_action
def group_list_uncoupled(by_dc=('', None, 'Group by dc and provide some useful data'),
                         json=('', None, 'Format additional data as json'),
                         host=None, app=None):
    '''Get list of uncoupled groups from balancer'''
    s = service(host, app)
    res = s.enqueue("get_empty_groups", "").get()

    if not by_dc:
        print res

    if by_dc:
        groups_by_dcs = s.enqueue('groups_by_dc',
            msgpack.packb((res,))).get()
        print_by_dcs(groups_by_dcs, json)


@groupDispatcher.command(name='detach-node')
@log_action
def group_detach_node(group, node=None,
                      host=None, app=None):
    '''Detach node from a group. Used when elliptics instance is
       transferred to another host and/or port.

       Node parameter is <host>:<port>'''
    s = service(host, app)

    if not node:
        res = s.enqueue('get_group_info', msgpack.packb(group)).get()
        pprint(res)
        print 'You have to select node to be detached (<host>:<port>)'
        return

    res = s.enqueue('group_detach_node', msgpack.packb([group, node])).get()
    print res


@groupDispatcher.command(name='force-update')
@log_action
def group_force_update(host=None, app=None):
    '''Force mastermind node data collection'''
    s = service(host, app)

    res = s.enqueue('force_nodes_update', '').get()
    print res


@groupDispatcher.command(name='move')
@log_action
def group_move(group, uncoupled_groups=('u', '', 'Use certain destination uncoupled groups '
                   '(use comma-separated list if you want to merge several uncoupled groups '
                   'into one)'),
               force=('f', False, 'Cancel all pending jobs of low priority '
                      '(e.g. recover-dc and defragmenation)'),
               host=None, app=None):
    '''Create job to move group's node backend to uncoupled group's node backend.
       Uncoupled group will be replaced, source group node backend will be disabled.
       Applicable only for single node backend groups'''
    s = service(host, app)

    group = int(group)

    if uncoupled_groups:
        uncoupled_groups = map(int, uncoupled_groups.split(','))
    else:
        uncoupled_groups = None

    job_data = s.enqueue('move_group', msgpack.packb([group,
        {'uncoupled_groups': uncoupled_groups}, force])).get()

    print job_data


@groupDispatcher.command(name='restore')
@log_action
def group_restore(group, uncoupled_group=('u', False, 'Use uncoupled group as '
                  'a restoration point instead of previous group location'),
                  src_group=('s', '', 'Use selected group as a source group to copy data from'),
                  force=('f', False, 'Cancel all pending jobs of low priority '
                      '(e.g. recover-dc and defragmenation)'),
                  host=None, app=None):
    '''Create job to restore group's node backend from a coupled group.
       By default data is being restored to the previous location
       of group's node backend. If uncoupled group is set, it's node backend
       will be used instead.
       Applicable only for single node backend groups'''
    s = service(host, app)

    group = int(group)

    job_data = s.enqueue('restore_group', msgpack.packb([
        group, uncoupled_group, {'src_group': src_group}, force])).get()

    print job_data


@groupDispatcher.command(name='recover-dc')
@log_action
def group_recover_dc(group,
                     host=None, app=None):
    '''Create job to perform dnet_recovery dc command on destination group's
    node backend'''
    s = service(host, app)

    group = int(group)

    couple_data = retry(s, 'get_couple_info', group)

    job_data = s.enqueue('create_job', msgpack.packb(['recover_dc_job',
        {'couple': couple_data['id']}])).get()

    print job_data


@groupDispatcher.command(name='search-by-path')
@log_action
def group_search_by_path(group_host, group_path,
                         json=('', None, 'Format additional data as json'),
                         last=('l', False, 'Search only within last history record'),
                         host=None, app=None):
    '''Search which group ever lived on a given path on a host'''
    s = service(host, app)

    try:
        ips = set()
        addrinfo = socket.getaddrinfo(group_host, 1025)
        for res in addrinfo:
            ips.add(res[4][0])
    except Exception:
        print warn('Failed to resolve hostname {0}'.format(group_host))
        return

    group_path = os.path.normpath(group_path) + '/'

    ips_res = []
    for ip in ips:
        res = s.enqueue('search_history_by_path', msgpack.packb([
            {'host': ip,
             'path': group_path,
             'last': last}])).get()

        if isinstance(res, dict):
            # error
            print res
        else:
            ips_res.extend(res)

    if json:
        print dumps(res)
        return

    print color('{0:^25} | {1:^10} | {2:^50} | {3:^15}'.format(
        'Date', 'Group id', 'Nodes', 'Type of record'), GREEN)
    for r in ips_res:
        for nodes in r['set'][:1]:
            print '{0:25} | {1:>10} | {2:50} | {3}'.format(
                ts_to_dt(r['timestamp']), r['group'], nodes, r['type'])
        for nodes in r['set'][1:]:
            print (' ' * 41) + '{0:50}'.format(nodes)


# couple commands
coupleDispatcher = Dispatcher(globaloptions=(host_param, app_param))


def deprecated(state, by_ns=None, by_dc=None, json=None):
    options = []
    if by_ns:
        options.append('--by-ns')
    elif by_dc:
        options.append('--by-dc')
    if not json:
        options.append('--short')

    print (warn('DEPRECATED: ') + 'use command "mastermind couple list --state {0}'
        '{1}"'.format(state, ' ' + ' '.join(options) if options else ''))


@coupleDispatcher.command(name='list-bad')
@log_action
def couple_list_bad(by_dc=('', None, 'Group by dc and provide some useful data'),
                    by_ns=('', None, 'Group by namespaces'),
                    json=('', None, 'Format additional data as json'),
                    host=None, app=None):
    '''Get list of broken couples from balancer'''
    deprecated('bad', by_ns=by_ns, by_dc=by_dc, json=json)

    s = service(host, app)
    res = s.enqueue('get_bad_groups', '').get()

    if not by_dc and not by_ns:
        print res

    if by_dc:
        groups_by_dcs = s.enqueue('groups_by_dc',
            msgpack.packb(([g for c in res for g in c],))).get()
        print_by_dcs(groups_by_dcs, json)
    if by_ns:
        couples_by_nss = s.enqueue('couples_by_namespace',
            msgpack.packb((res,))).get()
        print_by_namespaces(couples_by_nss, json)


@coupleDispatcher.command(name='list-symmetric')
@log_action
def couple_list_symmetric(by_dc=('', None, 'Group by dc and provide some useful data'),
                          by_ns=('', None, 'Group by namespaces'),
                          json=('', None, 'Format additional data as json'),
                          host=None, app=None):
    '''Get list of good couples from balancer'''
    deprecated('good', by_ns=by_ns, by_dc=by_dc, json=json)

    s = service(host, app)
    res = s.enqueue("get_symmetric_groups", "").get()

    if not by_dc and not by_ns:
        print res

    if by_dc:
        groups_by_dcs = s.enqueue('groups_by_dc',
            msgpack.packb(([g for c in res for g in c],))).get()
        print_by_dcs(groups_by_dcs, json)
    if by_ns:
        couples_by_nss = s.enqueue('couples_by_namespace',
            msgpack.packb((res,))).get()
        print_by_namespaces(couples_by_nss, json)


@coupleDispatcher.command(name='list-frozen')
@log_action
def couple_list_frozen(by_dc=('', None, 'Group by dc and provide some useful data'),
                       by_ns=('', None, 'Group by namespaces'),
                       json=('', None, 'Format additional data as json'),
                       host=None, app=None):
    '''Get list of frozen couples from balancer'''
    deprecated('frozen', by_ns=by_ns, by_dc=by_dc, json=json)

    s = service(host, app)
    res = s.enqueue("get_frozen_groups", "").get()

    if not by_dc and not by_ns:
        print res

    if by_dc:
        groups_by_dcs = s.enqueue('groups_by_dc',
            msgpack.packb(([g for c in res for g in c],))).get()
        print_by_dcs(groups_by_dcs, json)
    if by_ns:
        couples_by_nss = s.enqueue('couples_by_namespace',
            msgpack.packb((res,))).get()
        print_by_namespaces(couples_by_nss, json)


@coupleDispatcher.command(name='list-closed')
@log_action
def couple_list_closed(by_dc=('', None, 'Group by dc and provide some useful data'),
                       by_ns=('', None, 'Group by namespaces'),
                       json=('', None, 'Format additional data as json'),
                       host=None, app=None):
    '''Get list of couples closed to balancer'''
    deprecated('full', by_ns=by_ns, by_dc=by_dc, json=json)

    s = service(host, app)
    res = s.enqueue('get_closed_groups', '').get()

    if not by_dc and not by_ns:
        print res

    if by_dc:
        groups_by_dcs = s.enqueue('groups_by_dc',
            msgpack.packb(([g for c in res for g in c],))).get()
        print_by_dcs(groups_by_dcs, json)
    if by_ns:
        couples_by_nss = s.enqueue('couples_by_namespace',
            msgpack.packb((res,))).get()
        print_by_namespaces(couples_by_nss, json)


@coupleDispatcher.command(name='info')
@log_action
def couple_info(group, host=None, app=None):
    '''Get couple info'''
    s = service(host, app)
    group = int(group)

    res = s.enqueue("get_couple_info", msgpack.packb(group)).get()
    for group in res.get('groups', []):
        for node in group.get('node_backends', []):
            convert_stats(node)
    if 'id' in res:
        convert_stats(res)

    if 'Balancer error' in res or 'Error' in res:
        print res
        return

    print color('Groups info', YELLOW)
    pprint(res['groups'])

    print
    print color('Couple info', YELLOW)
    res['group_statuses'] = []
    for g in res['groups']:
        res['group_statuses'].append({'group_id': g['id'],
            'status': g['status'],
            'status_text': g['status_text']})
    del res['groups']
    pprint(res)


STATES = {
    'OK': 'good',
    'FULL': 'full',
    'FROZEN': 'frozen',
    'INIT': 'bad',
    'BAD': 'bad',
}


@coupleDispatcher.command(name='list')
@log_action
def couple_list(namespace=('n', '', 'Filter by namespace'),
                state=('s', '', 'Filter by state (good|full|frozen|bad)'),
                short=('', False, 'Use short format output'),
                verbose=('v', False, 'Use verbose format output'),
                by_ns=('', False, 'Output by namespaces'),
                by_dc=('', False, 'Output by dc'),
                by_state=('', False, 'Output by state'),
                json=('', False, 'Output in json format (overrided by --short and --verbose options)'),
                host=None, app=None):
    '''List couples with various view options. Default format is json,
    use '--short' or '--verbose' option for human readable formats.'''
    s = service(host, app)

    options = {'namespace': namespace,
               'state': state}
    couples = s.enqueue('get_couples_list', msgpack.packb([options])).get()

    viewer = view_couples
    data = couples

    grouped = by_ns or by_dc or by_state
    key_mapper = lambda k: k
    if grouped:
        if by_dc:
            viewer = view_groups
            data = group_by_dc(couples)
        elif by_ns:
            data = group_by_ns(couples)
        elif by_state:
            data = group_by_state(couples)
            key_mapper = lambda k: STATES.get(k, k)

    if not short and not verbose:

        # convert stats
        def convert_entities_stats(entities):

            def convert_group_stats(group):
                for node in group.get('node_backends', []):
                    convert_stats(node)

            for entity in entities:
                if 'couple_status' in entity:
                    # entity is couple
                    for group in entity.get('groups', []):
                        convert_group_stats(group)
                    convert_stats(entity)
                else:
                    # entity is group
                    convert_group_stats(entity)

        if grouped:
            for key, entities in data.iteritems():
                convert_entities_stats(entities)
        else:
            convert_entities_stats(data)

        if json:
            print dumps(data)
        else:
            pprint(data)
        return

    viewer(data, grouped, key_mapper, short=short, verbose=verbose)


def group_by_ns(couples):
    res = {}
    for c in couples:
        res.setdefault(c['namespace'], []).append(c)
    return res


def group_by_state(couples):
    res = {}
    for c in couples:
        res.setdefault(c['couple_status'], []).append(c)
    return res


def group_by_dc(couples):
    res = {}
    for c in couples:
        for g in c['groups']:
            dcs = set()
            for node in g['node_backends']:
                dcs.add(node['dc'])
            if not dcs:
                dcs.add('unknown')
            for dc in dcs:
                res.setdefault(dc, []).append(g)
    return res


def view_couples(data, grouped, key_mapper, short=False, verbose=False):

    def output(couples, short=False, verbose=False):
        if short:
            print tuple([c['tuple'] for c in couples])
        elif verbose:
            print '-' * 30
            for c in sorted(couples,
                            key=lambda x: (len(x['id'].split(':')), x['id'])):
                print_couple(c)

    if grouped:
        for k, couples in data.iteritems():
            print color(key_mapper(k), YELLOW)
            output(couples, short=short, verbose=verbose)
            print
    else:
        output(data, short=short, verbose=verbose)


def view_groups(data, grouped, key_mapper, short=False, verbose=False):

    def output(groups, short=False, verbose=False):
        if short:
            print tuple([g['id'] for g in groups])
        elif verbose:
            print '-' * 30
            for c in sorted(groups):
                print_group(c)

    if grouped:
        for k, groups in sorted(data.iteritems(),
                                key=lambda x: '' if x[0] == 'unknown' else x[0]):
            print color(key_mapper(k), YELLOW)
            output(groups, short=short, verbose=verbose)
            print
    else:
        output(groups, short=short, verbose=verbose)


ALLOWED_COUPLE_STATES = ('frozen', 'coupled')

@coupleDispatcher.command(name='build')
@log_action
def couple_build(size, groups=('i', [], 'Use these groups in couple (example: -i 1:2). '
                    'This option can be used multiple times, each successive groups '
                    'will be included in a separate couple'),
                 couples=('c', 1, 'Number of couples to create. Mastermind will try '
                    'to build couples using groups from different sets of dcs '
                    'to prevent all couples falling out when a dc gets disconnected'),
                 ignore_space=('s', False, 'Ignore checking of groups total space '
                    'matching'),
                 namespace=('n', '', 'Set custom namespace for couple'),
                 dry_run=('d', False, 'Dry-run mode'),
                 state=('', '', 'Set couple initial state (coupled|frozen)'), host=None, app=None):
    '''Make a couple of groups. The default behaviour is to use
    groups with approximately equal total space size.
    This behaviour can be turned off by --ignore-space option.
    Options --couples and --groups are mutually exclusive.
    The required argument for the command is the size of a couple (number of groups).'''
    s = service(host, app)
    size = int(size)

    if groups:
        groups = [g.split(':') for g in groups]
    else:
        groups = []

    if not namespace:
        print warn('Namespace should be set (--namespace | -n)')
        return 1

    if not state or not state.lower() in ALLOWED_COUPLE_STATES:
        print warn('Initial couple state is required (--state): coupled | frozen')
        return 1

    params = [size, couples, {'namespace': namespace,
                              'match_group_space': not ignore_space,
                              'init_state': state,
                              'dry_run': dry_run,
                              'mandatory_groups': groups}]

    res = s.enqueue('build_couples', msgpack.packb(params)).get()

    if not isinstance(res,  tuple):
        print res
        return 1

    good_couples, error = res

    if couples > 1:
        print highlight('Successfully created {0} out of {1} couples:'.format(len(good_couples), couples))
    for c in good_couples:
        print c

    if error:
        print warn("Exception occured: {0}".format(error))
    elif len(good_couples) < couples:
        print warn('Not enough valid dcs and/or groups of appropriate '
            'total space for remaining couples creation')

    if not len(good_couples):
        return 1

@coupleDispatcher.command(name='break')
@log_action
def couple_break(couple, confirm=None,
                 host=None, app=None):
    '''Break the couple of groups, couple is an argument
        confirm parameter is a message "Yes, I want to break (bad|good) couple [1:2:3]"'''
    s = service(host, app)
    groups = [int(g) for g in couple.split(':')]

    res = s.enqueue('break_couple', msgpack.packb((groups, confirm))).get()
    print res


@coupleDispatcher.command(name='weights')
@log_action
def couple_get_weights(namespace=('n', '', 'Use namespace for couple if there are '
                                      'no neighbour groups to fetch definite namespace'),
                       host=None, app=None):
    '''Get weights for symmetric groups'''
    s = service(host, app)
    params = []
    if namespace:
        params.append(namespace)
    res = s.enqueue("get_group_weights", msgpack.packb(params)).get()
    print res


@coupleDispatcher.command(name='repair')
@log_action
def couple_repair(group,
                  namespace=('n', '', 'Use namespace for couple if there are '
                                      'no neighbour groups to fetch definite namespace'),
                  host=None, app=None):
    '''Repair broken symmetric groups'''
    s = service(host, app)
    params = [int(group)]
    if namespace:
        params.append(namespace)

    res = s.enqueue("repair_groups", msgpack.packb(tuple(params))).get()
    print res


@coupleDispatcher.command(name='list-namespaces')
@log_action
def couple_list_namespaces(host=None, app=None):
    '''List all couple namespaces'''
    s = service(host, app)
    res = s.enqueue('get_namespaces', '').get()
    print res


# jobs commands
jobDispatcher = Dispatcher(globaloptions=(host_param, app_param))


@jobDispatcher.command(name='status')
@log_action
def job_status(job_id,
               json=('', None, 'Format data as json'),
               host=None, app=None):
    '''Get job status'''
    s = service(host, app)
    res = s.enqueue('get_job_status', msgpack.packb([job_id])).get()
    if json:
        print dumps(res)
    else:
        pprint(res)


@jobDispatcher.command(name='move-groups')
@log_action
def job_move_groups(src_host,
                    host=None, app=None):
    '''Create jobs to move all groups' node backends from source host.
       Mastermind will try to preserve namespace balance across storage.
       Applicable only for single node backend groups'''
    s = service(host, app)

    res = s.enqueue('move_groups_from_host', msgpack.packb([src_host])).get()

    if not 'jobs' in res:
        print res
        return 1

    if res['jobs']:
        print color('Created jobs:', GREEN)
        for job in res['jobs']:
            print '{group_id}: {job_id}'.format(group_id=job['group'], job_id=job['id'])
        print

    if res['failed']:
        print color('Failed groups', RED)
        for group_id, err in res['failed'].iteritems():
            print '{group_id}: {err}'.format(group_id=group_id, err=err)
        print


# namespace commands
nsDispatcher = Dispatcher(globaloptions=(host_param, app_param))

@nsDispatcher.command(name='setup')
@log_action
def ns_setup(namespace,
             overwrite=('o', False, 'Flag to setup namespace from scratch'),
             groups_count=('g', '', 'Set number of groups per couple'),
             success_copies=('s', '', 'Success copy politics (any|quorum|all)'),
             auth_key_write=('', '', 'Proxy auth-key for writing'),
             auth_key_read=('', '', 'Proxy auth-key for reading'),
             sign_token=('', '', 'Signature token'),
             sign_path_prefix=('', '', 'Signature path prefix'),
             min_units=('u', '', 'Minimal number of units available for write operations '
                'in namespace when namespace is considered alive'),
             couple=('c', '', 'Set static couple for namespace (1:2:10)'),
             redirect_content_length_threshold=('', '', 'Set content length threshold for '
                'proxy to return direct urls instead of balancer urls'),
             redirect_expire_time=('', '', 'Time for which redirect url is considered '
                'valid'),
             multipart_content_length_threshold=('', '', 'Set multipart feature '
                'content length threshold (multipart upload is enabled for '
                'requests with content length less than threshold)'),
             select_couple_to_upload=('', '', 'Client is allowed to select a couple '
                'to write key to (true|false)'),
             reserved_space_percentage=('', '', 'Percentage of effective space that '
                'will be reserved for future updates, couple will be closed when '
                'free effective space percentage is less than or equal to reserved '
                'space percentage'),
             check_for_update=('', '', 'Insert the key only of does not exist already (1|0)'),
             custom_expiration_time=('', '', 'Allows namespace to use expire-time '
                'argument for signing url (1|0)'),
             json_input=('j', False, 'Namespace settings will be imported without '
                'validation from --input-source source (default /dev/stdin)'),
             input_source=('i', '/dev/stdin', 'Input file for namespace settings'),
             host=None, app=None):
    '''Namespace setup.
    Updates settings by default with given keys.
    Use --overwrite to completely overwrite namespace settings.'''
    s = service(host, app)

    settings = {}
    options = {}

    if json_input:
        settings = open(input_source, 'rb').read()
        options['json'] = True
        options['skip_validation'] = True
    else:
        try:
            groups_count = int(groups_count)
        except ValueError:
            groups_count = 0

        if not success_copies and overwrite:
            print warn('--success-copies is required parameter')
            return

        if success_copies:
            settings['success-copies-num'] = success_copies

        if couple:
            couple = [int(g) for g in couple.split(':')]
        else:
            couple = None

        if (not couple and not groups_count) and overwrite:
            print warn('either --groups-count or --couple is required')
            return

        if couple:
            settings['static-couple'] = couple
        elif groups_count:
            settings['groups-count'] = groups_count
        if sign_token:
            settings.setdefault('signature', {})['token'] = sign_token
        if sign_path_prefix:
            settings.setdefault('signature', {})['path_prefix'] = sign_path_prefix
        if auth_key_read:
            settings.setdefault('auth-keys', {})['read'] = auth_key_read
        if auth_key_write:
            settings.setdefault('auth-keys', {})['write'] = auth_key_write
        if overwrite and (auth_key_read or auth_key_write):
            # set empty read or write key if not specified
            settings['auth-keys'].setdefault('read', '')
            settings['auth-keys'].setdefault('write', '')

        if min_units:
            settings['min-units'] = min_units
        if reserved_space_percentage:
            settings['reserved-space-percentage'] = reserved_space_percentage

        redirect = {}
        if redirect_content_length_threshold:
            redirect['content-length-threshold'] = int(redirect_content_length_threshold)
        if redirect_expire_time:
            redirect['expire-time'] = int(redirect_expire_time)

        if redirect:
            settings['redirect'] = redirect

        features = {}
        if multipart_content_length_threshold:
            features['multipart'] = {
                'content-length-threshold': int(multipart_content_length_threshold)
            }
        if select_couple_to_upload == 'true':
            features['select-couple-to-upload'] = True
        if custom_expiration_time:
            features['custom-expiration-time'] = custom_expiration_time != '0'

        if features:
            settings['features'] = features

        if check_for_update:
            settings['check-for-update'] = check_for_update != '0'

    res = s.enqueue('namespace_setup', msgpack.packb([namespace, overwrite, settings, options])).get()
    print res


@nsDispatcher.command(name='settings')
@log_action
def ns_settings(namespace,
                service_key=('s', False, 'Include namespace service information'),
                deleted=('d', False, 'Show namespace settings even if namespace '
                    'has been deleted'),
                host=None, app=None):
    '''Get namespace settings'''
    s = service(host, app)

    options = {'deleted': deleted}
    res = s.enqueue('get_namespace_settings', msgpack.packb([
        namespace, options])).get()
    if not service_key:
        res.pop('__service', None)

    print res


@nsDispatcher.command(name='delete')
@log_action
def ns_delete(namespace, host=None, app=None):
    '''Delete namespace'''
    s = service(host, app)

    res = s.enqueue('namespace_delete', msgpack.packb([namespace])).get()
    print res


# cache commands
cacheDispatcher = Dispatcher(globaloptions=(host_param, app_param))


@cacheDispatcher.command(name='keys')
@log_action
def cache_keys(host=None, app=None):
    '''Fetch cached keys'''
    s = service(host, app)

    res = s.enqueue('get_cached_keys', '').get()
    print res


@cacheDispatcher.command(name='keys-by-group')
@log_action
def cache_keys_by_group(group, host=None, app=None):
    '''Fetch cached keys for certain group id'''
    s = service(host, app)
    group = int(group)

    res = s.enqueue('get_cached_keys_by_group', msgpack.packb(group)).get()


@coupleDispatcher.command(name='freeze')
@log_action
def couple_freeze(couple, host=None, app=None):
    '''Freeze symmetric group (frozen couples are excluded from balancing)'''
    s = service(host, app)
    groups = [int(g) for g in couple.split(':')]

    res = s.enqueue('freeze_couple', msgpack.packb(groups)).get()
    print res


@coupleDispatcher.command(name='unfreeze')
@log_action
def couple_unfreeze(couple, host=None, app=None):
    '''Unfreeze symmetric group'''
    s = service(host, app)
    groups = [int(g) for g in couple.split(':')]

    res = s.enqueue('unfreeze_couple', msgpack.packb(groups)).get()
    print res


@coupleDispatcher.command(name='defrag')
@log_action
def couple_defrag(couple,
                  host=None, app=None):
    '''Create job to perform couple's groups defragmentation'''
    s = service(host, app)

    couple_data = retry(s, 'get_couple_info', couple.split(':')[0])
    if 'Error' in couple_data:
        print warn('Couple {0} is not found {1}'.format(couple, couple_data['Error']))
        return

    if couple_data['couple_status'] not in ('FULL', 'OK'):
        print warn('Couple {0} has status {1}, expected {2}'.format(
            couple, couple_data['couple_status'], ['FULL', 'OK']))
        return

    job_data = s.enqueue('create_job', msgpack.packb(['couple_defrag_job',
        {'couple': couple_data['id']}])).get()

    print job_data


# lock commands
lockDispatcher = Dispatcher(globaloptions=(host_param, app_param))

@lockDispatcher.command(name='host')
@log_action
def lock_host(lock_host,
              json=('', None, 'Format additional data as json'),
              host=None, app=None):
    '''Acquire lock on a host'''
    s = service(host, app)

    try:
        hostname = socket.gethostbyaddr(lock_host)[0]
    except Exception as e:
        print warn('Failed to resolve hostname {0}: {1}'.format(lock_host, e))
        return

    result = s.enqueue('host_acquire_lock', msgpack.packb([hostname])).get()

    if 'Error' in result:
        print result['Error']
        return 1

    print result


# unlock commands
unlockDispatcher = Dispatcher(globaloptions=(host_param, app_param))

@unlockDispatcher.command(name='host')
@log_action
def unlock_host(lock_host,
              json=('', None, 'Format additional data as json'),
              host=None, app=None):
    '''Release lock on a host'''
    s = service(host, app)

    try:
        hostname = socket.gethostbyaddr(lock_host)[0]
    except Exception as e:
        print warn('Failed to resolve hostname {0}: {1}'.format(lock_host, e))
        return

    result = s.enqueue('host_release_lock', msgpack.packb([hostname])).get()

    if 'Error' in result:
        print result['Error']
        return 1

    print result



DEFAULT = '\033[0m'
DEFAULT_BOLD = '\033[1m'
RED = '\033[1;31m'
GREEN = '\033[1;32m'
YELLOW = '\033[1;33m'
BLUE = '\033[1;34m'

def warn(s):
    return color(s, RED)

def highlight(s):
    return color(s, GREEN)

def color(s, color):
    return '{color}{text}{coloroff}'.format(color=color,
                                            text=s, coloroff=DEFAULT)

def box(text, caption=None):
    print
    print '=' * 8 + (' %s ' % caption) + '=' * (60 - (len(caption) + 10))
    print highlight(text)
    print '=' * 60
    print


PATH_RE = re.compile('/[^\s]*')
MIN_PATH_LENGTH = 7


def danger(cmd):
    for path in PATH_RE.findall(cmd):
        if len(path) < MIN_PATH_LENGTH:
            return True
    return False


def confirm(prompt, answer, prefix=''):
    if prefix:
        print prefix

    try:
        s = raw_input(prompt)
    except KeyboardInterrupt:
        s = ''
        print

    return s == answer


def cmd_dest(cmd):
    return cmd.split(' ')[-1]


def watch_progress(session, task_id):
    success = False
    status_errors = 0
    error_sleep_time = 3
    max_retries = 240 / error_sleep_time

    while True:
        try:
            status = session.enqueue('get_command', msgpack.packb([task_id])).get()
        except ServiceError:
            sleep(1)
            continue

        if not status.get('uid') == task_id:
            status_errors += 1
            if status_errors > max_retries:
                print
                print warn('Failed to fetch command status after {0} retries'.format(max_retries))
                print
                pprint(status)
                break
            sleep(error_sleep_time)
            continue

        status_errors = 0

        sys.stdout.write('\rProgress: {0:.2f}%'.format(status['progress'] * 100))

        sys.stdout.flush()

        if status['progress'] == 1.0:
            print
            pprint(status)
            if status['exit_code'] == 0:
                success = True
                print 'Task finished successfully'
            else:
                print 'Exit code: {exit_code}\n{exit_message}'.format(**status)
            break

        sleep(1)

    return success


def retry(session, method, *params, **kwargs):
    retries = kwargs.get('retries', 2)

    tries = 0
    while True:
        try:
            return session.enqueue(method, msgpack.packb(*params)).get()
        except ServiceError:
            tries += 1
            if tries > retries:
                print 'Failed to perform mastermind request: {0}, params {1}'.format(method, params)
                raise

            sleep(3)
            continue


# display-me-pretty formatters

def print_by_dcs(groups_by_dc, as_json):

    for dc in groups_by_dc:
        # print groups_by_dc[dc]
        groups_by_dc[dc] = groups_by_dc[dc].values()

    if as_json:
        print json.dumps(groups_by_dc, indent=4)
        return

    field_order = dict((y, x) for x, y in enumerate(['group', 'node_backends', 'couple']))

    for dc, groups in sorted(groups_by_dc.iteritems(), key=lambda x: '' if x[0] == 'unknown' else x[0]):
        print '\n' + '=' * 30
        print 'DC: {0}'.format(color(dc, YELLOW))
        print '=' * 30

        for group in groups:

            couple_status = group.get('couple_status', 'NOT IN COUPLE')
            group['couple'] = '{0}, status {1}'.format(group.get('couple'),
                couple_status if couple_status == 'OK' else warn(couple_status))

            nodes = []
            for nb in sorted(group['node_backends'], key=lambda x: x['addr']):
                node_status = (nb['status']
                               if nb['status'] == 'OK' else
                               warn(nb['status']))
                nodes.append('{0}, status {1}, path {2} ({3})'.format(
                             nb['addr'], node_status, nb.get('path', 'unknown'),
                             nb['last_stat_update']))
            group['node_backends'] = nodes

            for k, v in sorted(group.iteritems(),
                               key=lambda x: field_order.get(x[0], x[0])):
                if not k in field_order:
                    continue

                if k == 'node_backends':
                    for node in v[:1]:
                        print '{0:15}: {1}'.format(k, node)
                    for node in v[1:]:
                        print '{0:15}  {1}'.format('', node)
                    continue

                print '{0:15}: {1}'.format(k, v)

            print '-' * 30


def print_by_namespaces(couples_by_nss, as_json):

    if as_json:
        print json.dumps(couples_by_nss, indent=4)
        return

    field_order = dict((y, x) for x, y in enumerate(['couple', 'node_backends']))

    for ns, couples in sorted(couples_by_nss.iteritems(), key=lambda x: '' if x[0] == None else x[0]):
        print '\n' + '=' * 30
        print 'Namespace: {0}'.format(color(ns, YELLOW))
        print '=' * 30

        for couple in sorted(couples,
                        key=lambda x: (len(x['couple'].split(':')), x['couple'])):

            couple_status = couple['couple_status']
            couple['couple'] = '{0}, status {1}'.format(couple.get('couple'),
                couple_status if couple_status == 'OK' else warn(couple_status))

            nodes = []
            for nb in sorted(couple['node_backends'], key=lambda x: x['addr']):
                node_status = (nb['status']
                               if nb['status'] == 'OK' else
                               warn(nb['status']))
                nodes.append('{0}, status {1}, dc {2}, updated {3}'.format(
                             nb['addr'], node_status,
                             color(nb['dc'], DEFAULT_BOLD),
                             nb['last_stat_update']))
            couple['nodes'] = nodes

            for k, v in sorted(couple.iteritems()):
                if not k in field_order:
                    continue

                if k == 'node_backends':
                    for node in v[:1]:
                        print '{0:15}: {1}'.format(k, node)
                    for node in v[1:]:
                        print '{0:15}  {1}'.format('', node)
                    continue

                print '{0:15}: {1}'.format(k, v)

            print '-' * 30


def print_couple(couple):
    couple_status = couple['couple_status']
    couple_s = '{0}, status {1}'.format(couple['id'],
        couple_status if couple_status == 'OK' else warn(couple_status))

    print '{0:15}: {1}'.format('couple', couple_s)
    for group in couple['groups']:
        group_status = group['status']
        group_s = '{0}, status {1}'.format(group['id'],
            group_status if group_status == 'COUPLED' else warn(group_status))

        print '  {0:13}: {1}'.format('group', group_s)

        for i, nb in enumerate(group['node_backends']):
            node_status = nb['status']
            print '    {0:11}: {1}, status {2}, dc {3} ({4})'.format(
                'nodes' if i == 0 else '', nb['addr'], node_status,
                color(nb['dc'], DEFAULT_BOLD),
                nb['last_stat_update'])

    print '-' * 30


def print_group(group):
    group_status = group['status']
    group_s = '{0}, status {1}'.format(group['id'],
        group_status if group_status == 'COUPLED' else warn(group_status))
    print '{0:15}: {1}'.format('group', group_s)

    for i, nb in enumerate(group['node_backends']):
        node_status = nb['status']
        print '  {0:13}: {1}, status {2}, path {3} ({4})'.format(
            'nodes' if i == 0 else '', nb['addr'], node_status,
            nb.get('path', 'unknown'),
            nb['last_stat_update'])

    print '-' * 30


d = Dispatcher(globaloptions=(app_param,))
d.nest('group', groupDispatcher, 'Perform group action')
d.nest('couple', coupleDispatcher, 'Perform couple action')
d.nest('ns', nsDispatcher, 'Perform namespace action')
d.nest('cache', cacheDispatcher, 'Perform cache action')
d.nest('job', jobDispatcher, 'Perform jobs action')
d.nest('lock', lockDispatcher, 'Acquire locks on storage infrastructure nodes')
d.nest('unlock', unlockDispatcher, 'Release locks on storage infrastructure nodes')


def command_helper(argv):
    cmdtable = d.cmdtable
    for opt in sys.argv[1:]:

        if opt == '--commands':
            for c in cmdtable:
                print c
            return

        command = cmdtable.get(opt, None) and cmdtable[opt][0]
        if not isinstance(command, Dispatcher):
            for o in command.opts:
                if o.name:
                    print '--' + o.name
                else:
                    print '-' + o.short
            return
        cmdtable = command.cmdtable


if __name__ == '__main__':

    if '--commands' in sys.argv:
        command_helper(sys.argv)
        sys.exit(0)

    sys.exit(d.dispatch())
